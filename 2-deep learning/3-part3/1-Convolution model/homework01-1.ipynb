{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Convolutional Neural Networks: Step by Step——一步一步构建卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)  # 设置默认的绘图尺寸\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)  # 设置随机种子，确保生成的随机数可重复"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/robbertliu/deeplearning.ai-andrewNG/b18a671f605951642c7f450181e5764ce56b7048/COURSE%204%20Convolutional%20Neural%20Networks/Week%2001/images/model.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/robbertliu/deeplearning.ai-andrewNG/b18a671f605951642c7f450181e5764ce56b7048/COURSE%204%20Convolutional%20Neural%20Networks/Week%2001/images/conv_nn.png\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    在图像数据集X的所有图像周围填充零。填充应用于图像的高度和宽度.\n",
    "    \n",
    "    参数：\n",
    "    X -- 形状为(m, n_H, n_W, n_C)的Python numpy数组，表示m个图像的批处理\n",
    "    pad -- 整数，表示在每个图像的垂直和水平维度周围填充的数量\n",
    "    \n",
    "    返回：\n",
    "    X_pad -- 形状为(m, n_H + 2*pad, n_W + 2*pad, n_C)的填充图像\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), \"constant\")\n",
    "    \n",
    "    return X_pad\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/robbertliu/deeplearning.ai-andrewNG/b18a671f605951642c7f450181e5764ce56b7048/COURSE%204%20Convolutional%20Neural%20Networks/Week%2001/images/PAD.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "x[1,1] = [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] = [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19a25e664c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)  # 设置随机种子，保证结果可复现\n",
    "x = np.random.randn(4, 3, 3, 2)  # 创建一个随机数组，形状为 (4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)  # 对数组进行零填充，填充大小为 2\n",
    "print (\"x.shape =\", x.shape)  # 打印原始数组 x 的形状\n",
    "print (\"x_pad.shape =\", x_pad.shape)  # 打印零填充后的数组 x_pad 的形状\n",
    "print (\"x[1,1] =\", x[1,1])  # 打印原始数组 x 中索引为 (1, 1) 的元素\n",
    "print (\"x_pad[1,1] =\", x_pad[1,1])  # 打印零填充后的数组 x_pad 中索引为 (1, 1) 的元素\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)  # 创建一个包含两个子图的图像窗口\n",
    "axarr[0].set_title('x')  # 设置子图 0 的标题为 'x'\n",
    "axarr[0].imshow(x[0,:,:,0])  # 在子图 0 中绘制原始数组 x 的第一个通道\n",
    "axarr[1].set_title('x_pad')  # 设置子图 1 的标题为 'x_pad'\n",
    "axarr[1].imshow(x_pad[0,:,:,0])  # 在子图 1 中绘制零填充后的数组 x_pad 的第一个通道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    对前一层的输出激活的单个切片（a_slice_prev）应用由参数 W 定义的一个滤波器。\n",
    "    \n",
    "    参数：\n",
    "    a_slice_prev -- 输入数据的切片，形状为 (f, f, n_C_prev)\n",
    "    W -- 权重参数，窗口矩阵，形状为 (f, f, n_C_prev)\n",
    "    b -- 偏置参数，窗口矩阵，形状为 (1, 1, 1)\n",
    "    \n",
    "    返回：\n",
    "    Z -- 标量值，通过将滑动窗口 (W, b) 卷积到输入数据的切片上得到的结果\n",
    "    \"\"\"\n",
    "\n",
    "    # a_slice_prev 和 W 逐元素相乘，不添加偏置。\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    # 对 s 的所有元素求和。\n",
    "    Z = np.sum(s)\n",
    "    # 将偏置 b 加到 Z 上。将 b 转换为 float() 类型，使得 Z 成为标量值。\n",
    "    Z = Z + float(b)\n",
    "\n",
    "    return Z\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/robbertliu/deeplearning.ai-andrewNG/b18a671f605951642c7f450181e5764ce56b7048/COURSE%204%20Convolutional%20Neural%20Networks/Week%2001/images/Convolution_schematic.gif\" height=\"40%\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    实现卷积函数的前向传播\n",
    "    \n",
    "    参数：\n",
    "    A_prev -- 前一层的输出激活，numpy 数组，形状为 (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- 权重，numpy 数组，形状为 (f, f, n_C_prev, n_C)\n",
    "    b -- 偏置，numpy 数组，形状为 (1, 1, 1, n_C)\n",
    "    hparameters -- 包含 \"stride\" 和 \"pad\" 信息的 Python 字典\n",
    "        \n",
    "    返回：\n",
    "    Z -- 卷积输出，numpy 数组，形状为 (m, n_H, n_W, n_C)\n",
    "    cache -- 用于反向传播的值的缓存\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从 A_prev 的形状中提取维度（≈1 行代码）  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # 从 W 的形状中提取维度（≈1 行代码）\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # 从 \"hparameters\" 中获取信息（≈2 行代码）\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # 使用上述给定的公式计算 CONV 输出体积的维度。提示：使用 int() 进行向下取整。（≈2 行代码）\n",
    "    n_H = (n_H_prev - f + 2 * pad) // stride + 1\n",
    "    n_W = (n_W_prev - f + 2 * pad) // stride + 1\n",
    "    \n",
    "    # 使用零初始化输出体积 Z（≈1 行代码）\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # 通过对 A_prev 进行填充来创建 A_prev_pad\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                               # 遍历训练样本的批次\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]                              # 选择第 i 个训练样本的填充激活\n",
    "        for h in range(n_H):                           # 遍历输出体积的垂直轴\n",
    "            for w in range(n_W):                       # 遍历输出体积的水平轴\n",
    "                for c in range(n_C):                   # 遍历通道数（= #滤波器）的输出体积\n",
    "                    \n",
    "                    # 找到当前 \"slice\" 的角落坐标（≈4 行代码）\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + stride\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + stride\n",
    "                    \n",
    "                    # 使用角落坐标来定义 a_prev_pad 的（3D）切片（参见上面的提示）。 （≈1 行代码）\n",
    "                    a_slice_prev = a_prev_pad[vert_start : vert_end, horiz_start : horiz_end, : ]\n",
    "                    \n",
    "                    # 将（3D）切片与正确的滤波器 W 和偏置 b 进行卷积，得到一个输出神经元。 （≈1 行代码）\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
    "    \n",
    "    # 确保输出的形状正确\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # 将值保存在 \"cache\" 中，以便进行反向传播\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/robbertliu/deeplearning.ai-andrewNG/b18a671f605951642c7f450181e5764ce56b7048/COURSE%204%20Convolutional%20Neural%20Networks/Week%2001/images/vert_horiz_kiank.png\" height=\"40%\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z 的均值 = 0.048995203528855794\n",
      "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
      "  5.18531798  8.75898442]\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10, 4, 4, 3)  # 随机生成输入数据 A_prev，维度为 (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "W = np.random.randn(2, 2, 3, 8)  # 随机生成卷积核参数 W，维度为 (f, f, n_C_prev, n_C)\n",
    "b = np.random.randn(1, 1, 1, 8)  # 随机生成偏置项参数 b，维度为 (1, 1, 1, n_C)\n",
    "hparameters = {\"pad\": 2, \"stride\": 2}  # 设置填充和步幅参数\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)  # 执行前向传播计算卷积\n",
    "print(\"Z 的均值 =\", np.mean(Z))  # 输出 Z 的均值\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])  # 输出 Z 在指定位置的值\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])  # 输出 cache_conv 中的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def pool_forward(A_prev, hparameters, mode=\"max\"):\n",
    "    \"\"\"\n",
    "    实现池化层的前向传播\n",
    "    \n",
    "    参数：\n",
    "    A_prev -- 输入数据，维度为 (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- 包含 \"f\" 和 \"stride\" 的 Python 字典\n",
    "    mode -- 池化模式，字符串类型，可选 \"max\" 或 \"average\"\n",
    "    \n",
    "    返回：\n",
    "    A -- 池化层的输出，维度为 (m, n_H, n_W, n_C)\n",
    "    cache -- 在池化层反向传播中使用的缓存，包含输入数据和 hparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从输入形状中获取维度\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # 从 \"hparameters\" 中获取超参数\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # 定义输出的维度\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # 初始化输出矩阵 A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for i in range(m):                         # 遍历训练样本\n",
    "        for h in range(n_H):                     # 遍历输出体积的垂直轴\n",
    "            for w in range(n_W):                 # 遍历输出体积的水平轴\n",
    "                for c in range(n_C):            # 遍历输出体积的通道\n",
    "                    \n",
    "                    # 找到当前 \"slice\" 的角落位置 (≈4 行)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # 使用角落位置在 A_prev 的第 i 个训练样本的第 c 个通道上定义当前切片 (≈1 行)\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # 根据不同的模式计算池化操作，使用 if 语句区分模式，使用 np.max/np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # 在 \"cache\" 中存储输入数据和 hparameters，用于池化层的反向传播\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # 确保输出形状正确\n",
    "    assert A.shape == (m, n_H, n_W, n_C)\n",
    "    \n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A = [[[[1.74481176 0.86540763 1.13376944]]]\n",
      "\n",
      "\n",
      " [[[1.13162939 1.51981682 2.18557541]]]]\n",
      "\n",
      "mode = average\n",
      "A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]\n",
      "\n",
      "\n",
      " [[[-0.22154621  0.51716526  0.48155844]]]]\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "np.random.seed(1)\n",
    "# 创建输入数据A_prev，大小为(2, 4, 4, 3)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "# 设置池化层超参数，步长为2，过滤器大小为3\n",
    "hparameters = {\"stride\": 2, \"f\": 3}\n",
    "\n",
    "# 使用最大池化模式进行前向传播\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A)\n",
    "print()\n",
    "\n",
    "# 使用平均池化模式进行前向传播\n",
    "A, cache = pool_forward(A_prev, hparameters, mode=\"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    实现卷积层的反向传播\n",
    "    \n",
    "    参数：\n",
    "    dZ -- 损失函数相对于卷积层输出（Z）的梯度，形状为 (m, n_H, n_W, n_C) 的 numpy 数组\n",
    "    cache -- 用于 conv_backward() 的值的缓存，是 conv_forward() 的输出\n",
    "    \n",
    "    返回值：\n",
    "    dA_prev -- 损失函数相对于卷积层输入（A_prev）的梯度，形状为 (m, n_H_prev, n_W_prev, n_C_prev) 的 numpy 数组\n",
    "    dW -- 损失函数相对于卷积层权重（W）的梯度，形状为 (f, f, n_C_prev, n_C) 的 numpy 数组\n",
    "    db -- 损失函数相对于卷积层偏置（b）的梯度，形状为 (1, 1, 1, n_C) 的 numpy 数组\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # 从缓存中提取信息\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    # 从 A_prev 的形状中提取维度\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # 从 W 的形状中提取维度\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # 从 \"hparameters\" 中提取信息\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # 从 dZ 的形状中提取维度\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # 初始化 dA_prev, dW, db 的形状\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    # 对 A_prev 和 dA_prev 进行填充\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):                       # 遍历训练样本\n",
    "        \n",
    "        # 选择第 i 个训练样本的 A_prev_pad 和 dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
    "        da_prev_pad = dA_prev_pad[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                   # 遍历输出体积的垂直轴\n",
    "            for w in range(n_W):               # 遍历输出体积的水平轴\n",
    "                for c in range(n_C):           # 遍历输出体积的通道\n",
    "                    \n",
    "                    # 找到当前 \"slice\" 的角落坐标\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # 使用角落坐标定义来自 a_prev_pad 的切片\n",
    "                    a_slice = a_prev_pad[vert_start : vert_end, horiz_start : horiz_end, :]\n",
    "\n",
    "                    # 使用给定的代码公式更新窗口和滤波器参数的梯度\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # 将第 i 个训练样本的 dA_prev 设置为未填充的 da_prev_pad（提示：使用 X[pad:-pad, pad:-pad, :]）\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad : -pad, pad : -pad, :]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # 确保输出形状正确\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 1.4524377775388075\n",
      "dW_mean = 1.7269914583139097\n",
      "db_mean = 7.839232564616838\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)  # 设置随机种子，保证随机结果可复现\n",
    "\n",
    "# 调用 conv_backward 函数计算梯度\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "\n",
    "# 打印 dA、dW、db 的平均值\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    \"\"\"\n",
    "    从输入矩阵 x 创建一个掩码，以识别 x 中的最大值位置。\n",
    "    \n",
    "    参数：\n",
    "    x -- 形状为 (f, f) 的数组\n",
    "    \n",
    "    返回：\n",
    "    mask -- 形状与输入窗口相同的数组，包含 True 在对应 x 最大值位置处。\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = (x >= np.max(x))  # 创建一个掩码，将最大值位置设为 True\n",
    "    \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2, 3)  # 生成一个形状为 (2, 3) 的随机数组\n",
    "mask = create_mask_from_window(x)  # 使用 create_mask_from_window 函数生成掩码\n",
    "print('x = ', x)  # 打印数组 x\n",
    "print(\"mask = \", mask)  # 打印掩码 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \"\"\"\n",
    "    将输入值分布在维度shape的矩阵中\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- 输入的标量值\n",
    "    shape -- 输出矩阵的形状 (n_H, n_W)，我们想要在该矩阵中分布 dz 的值\n",
    "    \n",
    "    Returns:\n",
    "    a -- 大小为 (n_H, n_W) 的数组，其中我们分布了 dz 的值\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # 从形状中获取维度信息 (≈1行)\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # 计算要在矩阵中分布的值 (≈1行)\n",
    "    average = dz / (n_H * n_W)\n",
    "    \n",
    "    # 创建一个每个元素都是 \"average\" 值的矩阵 (≈1行)\n",
    "    a = average * np.ones((n_H, n_W))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# 测试 distribute_value 函数\n",
    "a = distribute_value(2, (2, 2))\n",
    "print('distributed value =', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode=\"max\"):\n",
    "    \"\"\"\n",
    "    实现池化层的反向传播\n",
    "    \n",
    "    参数：\n",
    "    dA -- 池化层输出的损失梯度，与 A 的形状相同\n",
    "    cache -- 池化层前向传播的缓存，包含输入和超参数\n",
    "    mode -- 池化模式，定义为字符串 (\"max\" 或 \"average\")\n",
    "    \n",
    "    返回：\n",
    "    dA_prev -- 池化层输入的损失梯度，与 A_prev 的形状相同\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # 从缓存中获取信息 (≈1 行)\n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # 从 \"hparameters\" 中获取超参数 (≈2 行)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "    # 从 A_prev 和 dA 的形状中获取维度信息 (≈2 行)\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "    # 初始化 dA_prev 为零数组 (≈1 行)\n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    \n",
    "    for i in range(m):                       # 遍历训练样本\n",
    "        \n",
    "        # 选择 A_prev 中的第 i 个训练样本 (≈1 行)\n",
    "        a_prev = A_prev[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                   # 遍历垂直轴\n",
    "            for w in range(n_W):               # 遍历水平轴\n",
    "                for c in range(n_C):           # 遍历通道 (深度)\n",
    "                    \n",
    "                    # 找到当前 \"slice\" 的角落坐标 (≈4 行)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # 根据不同模式计算反向传播\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        # 用角落坐标和 \"c\" 定义来自 a_prev 的当前 slice (≈1 行)\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        # 创建来自 a_prev_slice 的掩码 (≈1 行)\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        # 将 dA 中的正确条目乘以掩码并加到 dA_prev 上 (≈1 行)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += dA[i, h, w, c] * mask\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                        # 从 dA 中获取值 a (≈1 行)\n",
    "                        da = dA[i, h, w, c]\n",
    "                        # 定义滤波器的形状为 fxf (≈1 行)\n",
    "                        shape = (f, f)\n",
    "                        # 分布值以获取正确的 dA_prev 切片，即添加分布值 da (≈1 行)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += distribute_value(da, shape)\n",
    "                        \n",
    "    ### END CODE ###\n",
    "    \n",
    "    # 确保输出形状正确\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.          0.        ]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子，以确保随机数生成的结果可重现\n",
    "np.random.seed(1)\n",
    "# 创建一个形状为 (5, 5, 3, 2) 的随机数组\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "# 设定池化层的超参数\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "# 执行池化层的前向传播，返回池化后的输出 A 和缓存 cache\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "# 创建一个形状为 (5, 4, 2, 2) 的随机数组\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "# 使用池化层的反向传播计算出上一层的梯度 dA_prev（使用最大池化模式）\n",
    "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "# 输出反向传播中使用的池化模式为 \"max\"\n",
    "print(\"mode = max\")\n",
    "# 输出 dA 的平均值\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "# 输出 dA_prev 中索引为 (1, 1) 的值\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])\n",
    "# 空行，用于分隔输出\n",
    "print()\n",
    "# 使用池化层的反向传播计算出上一层的梯度 dA_prev（使用平均池化模式）\n",
    "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "# 输出反向传播中使用的池化模式为 \"average\"\n",
    "print(\"mode = average\")\n",
    "# 输出 dA 的平均值\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "# 输出 dA_prev 中索引为 (1, 1) 的值\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
